<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0041)https://people.eecs.berkeley.edu/~Ojha/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  </style>
  <link rel="icon" type="image/png" href="https://people.eecs.berkeley.edu/~Ojha/images/seal_icon.png">
  <script async="" src="./Utkarsh Ojha_files/analytics.js"></script><script type="text/javascript" src="./Utkarsh Ojha_files/hidebib.js"></script>
  <title>Utkarsh Ojha</title>
  <meta name="Utkarsh Ojha&#39;s Berkeley Homepage" http-equiv="Content-Type" content="Utkarsh Ojha&#39;s Berkeley Homepage">
  <link href="./Utkarsh Ojha_files/css" rel="stylesheet" type="text/css">
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-64069893-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="./Utkarsh Ojha_files/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" cellspacing="0" cellpadding="20">
  <tbody><tr><td>

<p align="center"><font size="7">Utkarsh Ojha</font><br>
    <b>Email</b>:
    <font id="email" style="display:inline;">uojha@ucdavis.edu</font>
  </p><table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  

  <tbody><tr>
    <td width="67%" valign="middle" align="justify">
    <p>I am a second year PhD student at <a href="https://www.ucdavis.edu/">UC Davis</a> working with Prof. <a href="http://web.cs.ucdavis.edu/~yjlee/">Yong Jae Lee</a>. I spent the last year working as a visiting scholar at UC Davis, wokring on weakly supervised methods for computer vision.</p>

    <p>I graduated from <a href="http://mnnit.ac.in">MNNIT Allahabad</a> with Bachelors in Computer Science and Engineering. I spent summer 2017 working with <a href="http://cds.iisc.ac.in/faculty/venky/">Prof. Venkatesh Babu</a> on adversarial machine leanrning. Prior to that in summer 2016, I interned at <a href="https://www.isro.gov.in/">Indian Space Research Organization</a>, working on high resolution image reconstruction.

    <p>I'm interested in better understanding the generative models for image synthesis.</p>
	    
    </a><p align="center"><a>
    </a><a href="https://drive.google.com/open?id=1vNagzZKYNcXXtgLqsWV8muQJj8WmuWpj">CV</a> | <a href="https://github.com/utkarshojha">Github</a> | <a href="https://scholar.google.com/citations?user=QGdSgfoAAAAJ&hl=en">Google Scholar</a> | <a href="https://www.linkedin.com/in/utkarsh-ojha-16a20b11b/">LinkedIn</a>
    </p>
    </td>

    <td width="33%"><a href="https://github.com/utkarshojha/utkarshojha.github.io/blob/master/Utkarsh%20Ojha_files/utkarsh.jpg"><img src="./Utkarsh Ojha_files/utkarsh.jpg" width="90%"></a></td>
  </tr>
</tbody></table>


<!--
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr><td>
    <sectionheading>News</sectionheading>
    <ul>
    <li> Serving as a reviewer for <a href="http://iccv2019.thecvf.com">ICCV'19</a>.  
    <li> Paper on unsupervised hierarchical disentanglement for image synthesis is accepted at <a href="cvpr2019.thecvf.com">CVPR'19</a> as <strong>oral</strong>.
    <li> Joined <a href="https://www.ucdavis.edu/">UC Davis</a> as a research scholar, working with Yong Jae Lee.</li> 
    <li> Paper on modelling universal adversarial perturbations accepted at <a href="cvpr2018.thecvf.com">CVPR'18</a>.</li>

    </ul>
  </td></tr>
</tbody></table>

-->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr><td><sectionheading>Research</sectionheading></td></tr>
</tbody></table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

  <tbody>


<tr>
    <td width="33%" valign="top" align="center"><a href=""><img src="./Utkarsh Ojha_files/nips2020_teaser.PNG" alt="sym" width="100%" style="border-style: none"></a>
    </td><td width="67%" valign="top">
      <p><a href="" id="ICMLW18">
      <img src="./Utkarsh Ojha_files/new.png" alt="[NEW]" width="6%" style="border-style: none">
      <heading>Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Class-Imbalanced Data
</heading></a><br>
      <strong>Utkarsh Ojha</strong>, Krishna Kumar Singh, Cho-Jui Hsieh, Yong Jae Lee<br>
      NeurIPS 2020<br>
      </p>

      <div class="paper" id="newinfogan2019">
      <a href="https://utkarshojha.github.io/elastic-infogan">Project page</a> |
      <a href="javascript:toggleblock(&#39;newinfogan2019_abs&#39;)">abstract</a> |   
      <a shape="rect" href="javascript:togglebib(&#39;mixmatch2019&#39;)" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1910.01112">arXiv</a> |
      <a href="https://github.com/utkarshojha/elastic-infogan">code</a> 
      <br>
      <br>

      <p align="justify"> <i id="newinfogan2019_abs" style="display: none;">We propose a novel unsupervised generative model, Elastic-InfoGAN, that learns to disentangle object identity from other low-level aspects in class-imbalanced datasets. We first investigate the issues surrounding the assumptions about uniformity made by InfoGAN, and demonstrate its ineffectiveness to properly disentangle object identity in imbalanced data. Our key idea is to make the discovery of the discrete latent factor of variation invariant to identity-preserving transformations in real images, and use that as the signal to learn the latent distribution's parameters. Experiments on both artificial (MNIST) and real-world (YouTube-Faces) datasets demonstrate the effectiveness of our approach in imbalanced data by: (i) better disentanglement of object identity as a latent factor of variation; and (ii) better approximation of class imbalance in the data, as reflected in the learned parameters of the latent distribution.</i></p>

<pre xml:space="preserve" style="display: none;">@inproceedings{ojha-arxiv2019,
  Author = {Ojha, Utkarsh and Singh, Krishna Kumar and Hsieh, Cho-Jui and Lee, Yong Jae},
  Title = {Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Imbalanced Data
},
  Booktitle = {NeurIPS},
  Year = {2020}
}
</pre>
      </div>
    </td>
  </tr>

	  

<tr>
    <td width="33%" valign="top" align="center"><a href="https://arxiv.org/abs/1911.11758"><img src="./Utkarsh Ojha_files/thumb.png" alt="sym" width="100%" style="border-style: none"></a>
    </td><td width="67%" valign="top">
      <p><a href="https://arxiv.org/abs/1911.11758" id="ICMLW18">
      <heading>MixNMatch: Multifactor Disentanglement and Encoding for Conditional Image Generation
</heading></a><br>
      Yuheng Li, Krishna Kumar Singh, <strong>Utkarsh Ojha</strong>, Yong Jae Lee<br>
      <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2020<br>
      </p>

      <div class="paper" id="mixmatch2019">
      <a href="https://arxiv.org/abs/1911.11758">arXiv</a> |
      <a href="javascript:toggleblock(&#39;mixmatch2019_abs&#39;)">abstract</a> |   
      <a shape="rect" href="javascript:togglebib(&#39;mixmatch2019&#39;)" class="togglebib">bibtex</a> |
      <a href="https://www.youtube.com/watch?v=w36vnkIbyjs&feature=youtu.be">video</a> |
      <a href="https://github.com/Yuheng-Li/MixNMatch">code</a> 
      <br>
      <br>

      <p align="justify"> <i id="mixmatch2019_abs" style="display: none;">We present MixNMatch, a conditional generative model that learns to disentangle and encode background, object pose, shape, and texture from real images with minimal supervision, for mix-and-match image generation. We build upon FineGAN, an unconditional generative model, to learn the desired disentanglement and image generator, and leverage adversarial joint image-code distribution matching to learn the latent factor encoders. MixNMatch requires bounding boxes during training to model background, but requires no other supervision. Through extensive experiments, we demonstrate MixNMatch's ability to accurately disentangle, encode, and combine multiple factors for mix-and-match image generation, including sketch2color, cartoon2img, and img2gif applications.</i></p>

<pre xml:space="preserve" style="display: none;">@inproceedings{li-arxiv2019,
  Author = {Li, Yuheng and Singh, Krishna Kumar and Ojha, Utkarsh and Lee, Yong Jae},
  Title = {MixNMatch: Multifactor Disentanglement and Encoding for Conditional Image Generation
},
  Booktitle = {arXiv:1911.11758},
  Year = {2019}
}
</pre>
      </div>
    </td>
  </tr>


<tr>
    <td width="33%" valign="top" align="center"><a href="http://krsingh.cs.ucdavis.edu/krishna_files/papers/finegan/index.html"><img src="./Utkarsh Ojha_files/finegan_teaser.png" alt="sym" width="100%" style="border-style: none"></a>
    </td><td width="67%" valign="top">
      <p><a href="http://krsingh.cs.ucdavis.edu/krishna_files/papers/finegan/index.html" id="ICMLW18">
      <heading>FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery</heading></a><br>
      Krishna Kumar Singh*, <strong>Utkarsh Ojha*</strong>, Yong Jae Lee<br>
      (* equal contribution)<br>
      <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2019<br>
      <strong><font color="red">Oral Presentation</font></strong>    	
      </p>

      <div class="paper" id="fingan2019">
      <a href="http://krsingh.cs.ucdavis.edu/krishna_files/papers/finegan/index.html">project webpage</a> |
      <a href="https://arxiv.org/abs/1811.11155">arXiv</a> |
      <a href="javascript:toggleblock(&#39;newinfogan2019_abs&#39;)">abstract</a> |
      <a shape="rect" href="javascript:togglebib(&#39;newinfogan2019&#39;)" class="togglebib">bibtex</a> |
      <a href="https://www.youtube.com/watch?v=tkk0SeWGu-8">video</a> |
      <a href="https://github.com/kkanshul/finegan">code</a> 
      <br>
      <br>

      <p align="justify"> <i id="newinfogan2019_abs" style="display: none;">We propose FineGAN, a novel unsupervised GAN framework, which disentangles the background, object shape, and object appearance to hierarchically generate images of fine-grained object categories. To disentangle the factors without any supervision, our key idea is to use information theory to associate each factor to a latent code, and to condition the relationships between the codes in a specific way to induce the desired hierarchy. Through extensive experiments, we show that FineGAN achieves the desired disentanglement to generate realistic and diverse images belonging to fine-grained classes of birds, dogs, and cars. Using FineGAN's automatically learned features, we also cluster real images as a first attempt at solving the novel problem of unsupervised fine-grained object category discovery.</i></p>

<pre xml:space="preserve" style="display: none;">@inproceedings{singh-arxiv2018,
  Author = {Singh, Krishna and Ojha, Utkarsh and
  Lee, Yong Jae},
  Title = {FineGAN: Unsupervised Hierarchical
 	   Disentanglement for Fine-Grained 
	   Object Generation and Discovery},
  Booktitle = {arXiv:1811.11155},
  Year = {2018}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a href="http://val.serc.iisc.ernet.in/nag/"><img src="./Utkarsh Ojha_files/nag_multiple.png" alt="sym" width="100%" style="border-style: none"></a>
    </td><td width="67%" valign="top">
      <p><a href="http://val.serc.iisc.ernet.in/nag/" id="CVPRW18">
      <heading>NAG: Network for Adversary Generation</heading></a><br>
      Konda Reddy Mopuri*, <strong>Utkarsh Ojha*</strong>, Utsav Garg, R. Venkatesh Babu <br>
      (*equal contribution)<br>
      <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018<br>
      </p>
	
      <div class="paper" id="cvprw18">
      <a href="http://val.serc.iisc.ernet.in/nag/">project webpage</a> |
      <a href="https://arxiv.org/abs/1712.03390">arXiv</a> |
      <a href="javascript:toggleblock(&#39;cvprw18_abs&#39;)">abstract</a> |
      <a shape="rect" href="javascript:togglebib(&#39;cvprw18&#39;)" class="togglebib">bibtex</a> |
      <a href="https://github.com/val-iisc/nag">code</a>
      <br>
      <p align="justify"> <i id="cvprw18_abs" style="display: none;">Adversarial perturbations can pose a serious threat for deploying machine learning systems. Recent works have shown existence of image-agnostic perturbations that can fool classifiers over most natural images. Existing methods present optimization approaches that solve for a fooling objective with an imperceptibility constraint to craft the perturbations. However, for a given classifier, they generate one perturbation at a time, which is a single instance from the manifold of adversarial perturbations. Also, in order to build robust models, it is essential to explore the manifold of adversarial perturbations. In this paper, we propose for the first time, a generative approach to model the distribution of adversarial perturbations. The architecture of the proposed model is inspired from that of GANs and is trained using fooling and diversity objectives. Our trained generator network attempts to capture the distribution of adversarial perturbations for a given classifier and readily generates a wide variety of such perturbations. Our experimental evaluation demonstrates that perturbations crafted by our model (i) achieve state-of-the-art fooling rates, (ii) exhibit wide variety and (iii) deliver excellent cross model generalizability. Our work can be deemed as an important step in the process of inferring about the complex manifolds of adversarial perturbations.</i></p>

<pre xml:space="preserve" style="display: none;">@inproceedings{Mopuri_2018_CVPR,
      Author = {Reddy Mopuri, Konda and
      Ojha, Utkarsh and Garg, Utsav and
      Venkatesh Babu, R.},
      Title = {NAG: Network for 
		Adversary Generation},
      Booktitle = {The IEEE Conference on Computer
      Vision and Pattern Recognition (CVPR)},
      Year = {2018}
  }
</pre>
      </div>
    </td>
  </tr>


</tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr><td><br><p align="right"><font size="2">
    Template taken from <a href="http://www.cs.berkeley.edu/~barron/">here</a>
    </font></p></td></tr>
</tbody></table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('jpm15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('fg15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('wacv15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('iclr15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cvpr15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('iccv15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('jmlr16_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cvpr16_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('iclr16_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cvpr17_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('icml17_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('nips17_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('iclr18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('iclrw18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cvprw18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('largeScaleCuriosity2018_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('compgan18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('finegan2019_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('newinfogan2019_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('mixmatch2019_abs');
</script>





</body></html>
